{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "np.random.seed(1234)\n",
    "#def randomize(): np.random.seed(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cnt, output_cnt = 10,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RND_MEAN = 0\n",
    "RND_STD = 0.0030\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_abalone_dataset():\n",
    "    global dataset, answer\n",
    "    data = pd.read_csv('abalone.csv')\n",
    "    dataset = np.zeros([len(data), input_cnt + output_cnt]) # 0으로 채워진 table을 만들고, 전처리에 쓸 자료 채울 예정\n",
    "    # dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    \n",
    "    # 성별을 숫자로 one-hot encoding\n",
    "    for i in data.index:\n",
    "        row = data.loc[i]\n",
    "        if row[0] == 'I':\n",
    "            dataset[i,0] =1\n",
    "        elif row[0] == 'M':\n",
    "            dataset[i,1] =1\n",
    "        elif row[0] == 'F':\n",
    "            dataset[i,2] =1\n",
    "        dataset[i, 3:] = np.asarray(row[1:]) # 성별이 0,1,2열을 차지하고, 3부터는 원래의 데이터로 채움 \n",
    "    dataset.astype('float')\n",
    "    # Rings    \n",
    "    answer = dataset[:, -1] \n",
    "    # Sex,Length,Diameter,Height,Whole weight,Shucked weight,Viscera weight,Shell weight\n",
    "    dataset = dataset[:,:-1] \n",
    "    #X_train, X_validation, Y_train, Y_validation = train_test_split(dataset, answer, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(learning_rate):\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras import losses, optimizers\n",
    "    from tensorflow.keras.layers import Input, Dense\n",
    "    \n",
    "    inputs = Input(shape=(input_cnt,))\n",
    "    #x = Dense(32)(inputs)\n",
    "    outputs = Dense(output_cnt)(inputs)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam',\n",
    "                #loss = 'binary_crossentropy',\n",
    "                #loss=losses.mean_squared_error, \n",
    "                #optimizer = keras.optimizers.SGD(learning_rate=learning_rate), \n",
    "                  metrics = ['accuracy'])\n",
    "    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(epoch_count, mb_size, model):\n",
    "    model.fit(x = dataset, y = answer, batch_size = mb_size, epochs = epoch_count)\n",
    "    model.evaluate(x = dataset, y = answer, batch_size = mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abalone_exec(epoch_count = 10, mb_size=10, learning_rate = LEARNING_RATE):\n",
    "    load_abalone_dataset() # 자료 불러오기 \n",
    "    model = init_model(learning_rate) # 초기화 \n",
    "    train_and_test(epoch_count, mb_size, model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/a1/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/100\n",
      "4177/4177 [==============================] - 2s 383us/sample - loss: 78.9073 - acc: 2.3941e-04\n",
      "Epoch 2/100\n",
      "4177/4177 [==============================] - 1s 290us/sample - loss: 52.4519 - acc: 2.3941e-04\n",
      "Epoch 3/100\n",
      "4177/4177 [==============================] - 1s 260us/sample - loss: 34.2310 - acc: 2.3941e-04\n",
      "Epoch 4/100\n",
      "4177/4177 [==============================] - 1s 232us/sample - loss: 22.3356 - acc: 2.3941e-04\n",
      "Epoch 5/100\n",
      "4177/4177 [==============================] - 1s 225us/sample - loss: 15.1378 - acc: 2.3941e-04\n",
      "Epoch 6/100\n",
      "4177/4177 [==============================] - 1s 219us/sample - loss: 11.1840 - acc: 2.3941e-04\n",
      "Epoch 7/100\n",
      "4177/4177 [==============================] - 1s 225us/sample - loss: 9.2700 - acc: 2.3941e-04\n",
      "Epoch 8/100\n",
      "4177/4177 [==============================] - 1s 225us/sample - loss: 8.4660 - acc: 2.3941e-04s - loss: 8.5488 - acc: 3.28\n",
      "Epoch 9/100\n",
      "4177/4177 [==============================] - 1s 224us/sample - loss: 8.1548 - acc: 2.3941e-04\n",
      "Epoch 10/100\n",
      "4177/4177 [==============================] - 1s 220us/sample - loss: 8.0061 - acc: 2.3941e-04\n",
      "Epoch 11/100\n",
      "4177/4177 [==============================] - 1s 227us/sample - loss: 7.8930 - acc: 2.3941e-04\n",
      "Epoch 12/100\n",
      "4177/4177 [==============================] - 1s 210us/sample - loss: 7.7873 - acc: 2.3941e-04\n",
      "Epoch 13/100\n",
      "4177/4177 [==============================] - 1s 214us/sample - loss: 7.6835 - acc: 2.3941e-04\n",
      "Epoch 14/100\n",
      "4177/4177 [==============================] - 1s 204us/sample - loss: 7.5825 - acc: 2.3941e-04\n",
      "Epoch 15/100\n",
      "4177/4177 [==============================] - 1s 252us/sample - loss: 7.4854 - acc: 2.3941e-04\n",
      "Epoch 16/100\n",
      "4177/4177 [==============================] - 1s 257us/sample - loss: 7.3923 - acc: 2.3941e-04\n",
      "Epoch 17/100\n",
      "4177/4177 [==============================] - 1s 212us/sample - loss: 7.3056 - acc: 2.3941e-04\n",
      "Epoch 18/100\n",
      "4177/4177 [==============================] - 1s 254us/sample - loss: 7.2255 - acc: 2.3941e-04\n",
      "Epoch 19/100\n",
      "4177/4177 [==============================] - 1s 207us/sample - loss: 7.1495 - acc: 2.3941e-04\n",
      "Epoch 20/100\n",
      "4177/4177 [==============================] - 1s 239us/sample - loss: 7.0809 - acc: 2.3941e-04\n",
      "Epoch 21/100\n",
      "4177/4177 [==============================] - 1s 217us/sample - loss: 7.0155 - acc: 2.3941e-04\n",
      "Epoch 22/100\n",
      "4177/4177 [==============================] - 1s 207us/sample - loss: 6.9569 - acc: 2.3941e-04\n",
      "Epoch 23/100\n",
      "4177/4177 [==============================] - 1s 203us/sample - loss: 6.9021 - acc: 2.3941e-04\n",
      "Epoch 24/100\n",
      "4177/4177 [==============================] - 1s 203us/sample - loss: 6.8499 - acc: 2.3941e-04\n",
      "Epoch 25/100\n",
      "4177/4177 [==============================] - 1s 204us/sample - loss: 6.8058 - acc: 2.3941e-04\n",
      "Epoch 26/100\n",
      "4177/4177 [==============================] - 1s 197us/sample - loss: 6.7642 - acc: 2.3941e-04\n",
      "Epoch 27/100\n",
      "4177/4177 [==============================] - 1s 227us/sample - loss: 6.7249 - acc: 2.3941e-04\n",
      "Epoch 28/100\n",
      "4177/4177 [==============================] - 1s 219us/sample - loss: 6.6883 - acc: 2.3941e-04\n",
      "Epoch 29/100\n",
      "4177/4177 [==============================] - 1s 200us/sample - loss: 6.6566 - acc: 2.3941e-04\n",
      "Epoch 30/100\n",
      "4177/4177 [==============================] - 1s 200us/sample - loss: 6.6246 - acc: 2.3941e-04\n",
      "Epoch 31/100\n",
      "4177/4177 [==============================] - 1s 213us/sample - loss: 6.5954 - acc: 2.3941e-04\n",
      "Epoch 32/100\n",
      "4177/4177 [==============================] - 1s 199us/sample - loss: 6.5701 - acc: 2.3941e-04\n",
      "Epoch 33/100\n",
      "4177/4177 [==============================] - 1s 190us/sample - loss: 6.5443 - acc: 2.3941e-04\n",
      "Epoch 34/100\n",
      "4177/4177 [==============================] - 1s 266us/sample - loss: 6.5198 - acc: 2.3941e-04\n",
      "Epoch 35/100\n",
      "4177/4177 [==============================] - 1s 218us/sample - loss: 6.4980 - acc: 2.3941e-04\n",
      "Epoch 36/100\n",
      "4177/4177 [==============================] - 1s 224us/sample - loss: 6.4787 - acc: 2.3941e-04\n",
      "Epoch 37/100\n",
      "4177/4177 [==============================] - 1s 227us/sample - loss: 6.4580 - acc: 2.3941e-04\n",
      "Epoch 38/100\n",
      "4177/4177 [==============================] - 1s 201us/sample - loss: 6.4372 - acc: 2.3941e-04\n",
      "Epoch 39/100\n",
      "4177/4177 [==============================] - 1s 199us/sample - loss: 6.4195 - acc: 2.3941e-04\n",
      "Epoch 40/100\n",
      "4177/4177 [==============================] - 1s 217us/sample - loss: 6.4011 - acc: 2.3941e-04\n",
      "Epoch 41/100\n",
      "4177/4177 [==============================] - 1s 203us/sample - loss: 6.3834 - acc: 2.3941e-04\n",
      "Epoch 42/100\n",
      "4177/4177 [==============================] - 1s 204us/sample - loss: 6.3661 - acc: 2.3941e-04\n",
      "Epoch 43/100\n",
      "4177/4177 [==============================] - 1s 210us/sample - loss: 6.3496 - acc: 2.3941e-04s - loss: 6.2806 - acc: 2.5575e-\n",
      "Epoch 44/100\n",
      "4177/4177 [==============================] - 1s 198us/sample - loss: 6.3333 - acc: 2.3941e-04\n",
      "Epoch 45/100\n",
      "4177/4177 [==============================] - 1s 195us/sample - loss: 6.3173 - acc: 2.3941e-04\n",
      "Epoch 46/100\n",
      "4177/4177 [==============================] - 1s 201us/sample - loss: 6.3018 - acc: 2.3941e-04\n",
      "Epoch 47/100\n",
      "4177/4177 [==============================] - 1s 196us/sample - loss: 6.2863 - acc: 2.3941e-04\n",
      "Epoch 48/100\n",
      "4177/4177 [==============================] - 1s 205us/sample - loss: 6.2714 - acc: 2.3941e-04\n",
      "Epoch 49/100\n",
      "4177/4177 [==============================] - 1s 196us/sample - loss: 6.2573 - acc: 2.3941e-04\n",
      "Epoch 50/100\n",
      "4177/4177 [==============================] - 1s 202us/sample - loss: 6.2433 - acc: 2.3941e-04\n",
      "Epoch 51/100\n",
      "4177/4177 [==============================] - 1s 207us/sample - loss: 6.2303 - acc: 2.3941e-04\n",
      "Epoch 52/100\n",
      "4177/4177 [==============================] - 1s 198us/sample - loss: 6.2138 - acc: 2.3941e-04\n",
      "Epoch 53/100\n",
      "4177/4177 [==============================] - 1s 188us/sample - loss: 6.2034 - acc: 2.3941e-04\n",
      "Epoch 54/100\n",
      "4177/4177 [==============================] - 1s 202us/sample - loss: 6.1878 - acc: 2.3941e-04\n",
      "Epoch 55/100\n",
      "4177/4177 [==============================] - 1s 205us/sample - loss: 6.1765 - acc: 2.3941e-04\n",
      "Epoch 56/100\n",
      "4177/4177 [==============================] - 1s 197us/sample - loss: 6.1649 - acc: 2.3941e-04\n",
      "Epoch 57/100\n",
      "4177/4177 [==============================] - 1s 187us/sample - loss: 6.1511 - acc: 2.3941e-04\n",
      "Epoch 58/100\n",
      "4177/4177 [==============================] - 1s 200us/sample - loss: 6.1387 - acc: 2.3941e-04\n",
      "Epoch 59/100\n",
      "4177/4177 [==============================] - 1s 212us/sample - loss: 6.1266 - acc: 2.3941e-04\n",
      "Epoch 60/100\n",
      "4177/4177 [==============================] - 1s 200us/sample - loss: 6.1149 - acc: 2.3941e-04\n",
      "Epoch 61/100\n",
      "4177/4177 [==============================] - 1s 200us/sample - loss: 6.1016 - acc: 2.3941e-04\n",
      "Epoch 62/100\n",
      "4177/4177 [==============================] - 1s 212us/sample - loss: 6.0910 - acc: 2.3941e-04\n",
      "Epoch 63/100\n",
      "4177/4177 [==============================] - 1s 201us/sample - loss: 6.0791 - acc: 2.3941e-04\n",
      "Epoch 64/100\n",
      "4177/4177 [==============================] - 1s 186us/sample - loss: 6.0666 - acc: 2.3941e-04\n",
      "Epoch 65/100\n",
      "4177/4177 [==============================] - 1s 211us/sample - loss: 6.0565 - acc: 2.3941e-04\n",
      "Epoch 66/100\n",
      "4177/4177 [==============================] - 1s 194us/sample - loss: 6.0435 - acc: 2.3941e-04\n",
      "Epoch 67/100\n",
      "4177/4177 [==============================] - 1s 200us/sample - loss: 6.0319 - acc: 2.3941e-04\n",
      "Epoch 68/100\n",
      "4177/4177 [==============================] - 1s 202us/sample - loss: 6.0218 - acc: 2.3941e-04\n",
      "Epoch 69/100\n",
      "4177/4177 [==============================] - 1s 195us/sample - loss: 6.0107 - acc: 2.3941e-04\n",
      "Epoch 70/100\n",
      "4177/4177 [==============================] - 1s 207us/sample - loss: 5.9999 - acc: 2.3941e-04\n",
      "Epoch 71/100\n",
      "4177/4177 [==============================] - 1s 189us/sample - loss: 5.9877 - acc: 2.3941e-04\n",
      "Epoch 72/100\n",
      "4177/4177 [==============================] - 1s 214us/sample - loss: 5.9779 - acc: 2.3941e-04\n",
      "Epoch 73/100\n",
      "4177/4177 [==============================] - 1s 192us/sample - loss: 5.9670 - acc: 2.3941e-04\n",
      "Epoch 74/100\n",
      "4177/4177 [==============================] - 1s 204us/sample - loss: 5.9553 - acc: 2.3941e-04\n",
      "Epoch 75/100\n",
      "4177/4177 [==============================] - 1s 197us/sample - loss: 5.9464 - acc: 2.3941e-04\n",
      "Epoch 76/100\n",
      "4177/4177 [==============================] - 1s 202us/sample - loss: 5.9353 - acc: 2.3941e-04\n",
      "Epoch 77/100\n",
      "4177/4177 [==============================] - 1s 218us/sample - loss: 5.9247 - acc: 2.3941e-04\n",
      "Epoch 78/100\n",
      "4177/4177 [==============================] - 1s 274us/sample - loss: 5.9146 - acc: 2.3941e-04\n",
      "Epoch 79/100\n",
      "4177/4177 [==============================] - 1s 280us/sample - loss: 5.9037 - acc: 2.3941e-04\n",
      "Epoch 80/100\n",
      "4177/4177 [==============================] - 1s 253us/sample - loss: 5.8940 - acc: 2.3941e-04\n",
      "Epoch 81/100\n",
      "4177/4177 [==============================] - 1s 245us/sample - loss: 5.8845 - acc: 2.3941e-04\n",
      "Epoch 82/100\n",
      "4177/4177 [==============================] - 1s 224us/sample - loss: 5.8750 - acc: 2.3941e-04\n",
      "Epoch 83/100\n",
      "4177/4177 [==============================] - 1s 255us/sample - loss: 5.8642 - acc: 2.3941e-04\n",
      "Epoch 84/100\n",
      "4177/4177 [==============================] - 1s 254us/sample - loss: 5.8550 - acc: 2.3941e-04\n",
      "Epoch 85/100\n",
      "4177/4177 [==============================] - 1s 264us/sample - loss: 5.8451 - acc: 2.3941e-04\n",
      "Epoch 86/100\n",
      "4177/4177 [==============================] - 1s 235us/sample - loss: 5.8378 - acc: 2.3941e-04\n",
      "Epoch 87/100\n",
      "4177/4177 [==============================] - 1s 265us/sample - loss: 5.8263 - acc: 2.3941e-04\n",
      "Epoch 88/100\n",
      "4177/4177 [==============================] - 1s 252us/sample - loss: 5.8171 - acc: 2.3941e-04\n",
      "Epoch 89/100\n",
      "4177/4177 [==============================] - 1s 211us/sample - loss: 5.8057 - acc: 2.3941e-04\n",
      "Epoch 90/100\n",
      "4177/4177 [==============================] - 1s 254us/sample - loss: 5.7972 - acc: 2.3941e-04\n",
      "Epoch 91/100\n",
      "4177/4177 [==============================] - 1s 231us/sample - loss: 5.7871 - acc: 2.3941e-04\n",
      "Epoch 92/100\n",
      "4177/4177 [==============================] - 1s 263us/sample - loss: 5.7809 - acc: 2.3941e-04\n",
      "Epoch 93/100\n",
      "4177/4177 [==============================] - 1s 228us/sample - loss: 5.7692 - acc: 2.3941e-04\n",
      "Epoch 94/100\n",
      "4177/4177 [==============================] - 1s 226us/sample - loss: 5.7631 - acc: 2.3941e-04\n",
      "Epoch 95/100\n",
      "4177/4177 [==============================] - 1s 240us/sample - loss: 5.7534 - acc: 2.3941e-04\n",
      "Epoch 96/100\n",
      "4177/4177 [==============================] - 1s 259us/sample - loss: 5.7449 - acc: 2.3941e-04\n",
      "Epoch 97/100\n",
      "4177/4177 [==============================] - 1s 207us/sample - loss: 5.7368 - acc: 2.3941e-04\n",
      "Epoch 98/100\n",
      "4177/4177 [==============================] - 1s 204us/sample - loss: 5.7255 - acc: 2.3941e-04\n",
      "Epoch 99/100\n",
      "4177/4177 [==============================] - 1s 202us/sample - loss: 5.7197 - acc: 2.3941e-04\n",
      "Epoch 100/100\n",
      "4177/4177 [==============================] - 1s 207us/sample - loss: 5.7088 - acc: 2.3941e-04\n",
      "4177/4177 [==============================] - 1s 129us/sample - loss: 5.7048 - acc: 2.3941e-04\n"
     ]
    }
   ],
   "source": [
    "abalone_exec(epoch_count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
