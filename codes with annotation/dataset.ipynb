{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run mathutil.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, name, mode):\n",
    "        self.name = name # dataset 이름 \n",
    "        self.mode = mode # 출력 유형 \n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}({}, {}+{}+{})'.format(self.name, self.mode, \\\n",
    "                   len(self.tr_xs), len(self.te_xs), len(self.va_xs))\n",
    "\n",
    "    @property # decorator; 실제로는 method 지만 속성으로 취금됨; a.train_count 형식으로 접근 가능 \n",
    "    def train_count(self):\n",
    "        return len(self.tr_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_get_train_data(self, batch_size, nth): # mini batch train data 공급\n",
    "    from_idx = nth * batch_size\n",
    "    to_idx = (nth + 1) * batch_size\n",
    "\n",
    "    tr_X = self.tr_xs[self.indices[from_idx:to_idx]]\n",
    "    tr_Y = self.tr_ys[self.indices[from_idx:to_idx]]\n",
    "\n",
    "    return tr_X, tr_Y\n",
    "\n",
    "\n",
    "def dataset_shuffle_train_data(self, size): # 학습용 데이터 섞어줌 \n",
    "    self.indices = np.arange(size)\n",
    "    np.random.shuffle(self.indices)\n",
    "\n",
    "Dataset.get_train_data = dataset_get_train_data\n",
    "Dataset.shuffle_train_data = dataset_shuffle_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_get_test_data(self):\n",
    "    # 미리 준비된 test data set 입출력 성분 전체를 반환 \n",
    "    return self.te_xs, self.te_ys\n",
    "\n",
    "Dataset.get_test_data = dataset_get_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_get_validate_data(self, count): # validation data의 일부를 반환 \n",
    "    self.va_indices = np.arange(len(self.va_xs))\n",
    "        # 선택된 data에 대한 추가 정보가 필요할 때를 위한 va_indices \n",
    "    np.random.shuffle(self.va_indices)\n",
    "\n",
    "    va_X = self.va_xs[self.va_indices[0:count]]\n",
    "    va_Y = self.va_ys[self.va_indices[0:count]]\n",
    "\n",
    "    return va_X, va_Y\n",
    "\n",
    "Dataset.get_validate_data = dataset_get_validate_data\n",
    "Dataset.get_visualize_data = dataset_get_validate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_shuffle_data(self, xs, ys, tr_ratio=0.8, va_ratio=0.05): # 파생 class들이 이용할 method \n",
    "    # 지정한 비율에 따라 test, train, validation data 개수 계산 \n",
    "    data_count = len(xs)\n",
    "    tr_cnt = int(data_count * tr_ratio / 10) * 10\n",
    "    va_cnt = int(data_count * va_ratio)\n",
    "    te_cnt = data_count - (tr_cnt + va_cnt)\n",
    "    # 데이터 수에 따라 세 영역의 구간 시작과 끝 위치를 계산 \n",
    "    tr_from, tr_to = 0, tr_cnt\n",
    "    va_from, va_to = tr_cnt, tr_cnt + va_cnt\n",
    "    te_from, te_to = tr_cnt + va_cnt, data_count\n",
    "    # data 뒤섞기용 indices \n",
    "    indices = np.arange(data_count)\n",
    "    np.random.shuffle(indices)\n",
    "    # 준비된 정보에 따라 data를 세 영역으로 분리해 저장 \n",
    "    self.tr_xs = xs[indices[tr_from:tr_to]]\n",
    "    self.tr_ys = ys[indices[tr_from:tr_to]]\n",
    "    self.va_xs = xs[indices[va_from:va_to]]\n",
    "    self.va_ys = ys[indices[va_from:va_to]]\n",
    "    self.te_xs = xs[indices[te_from:te_to]]\n",
    "    self.te_ys = ys[indices[te_from:te_to]]\n",
    "    # data 형태를 조사하여 저장 \n",
    "    self.input_shape = xs[0].shape\n",
    "    self.output_shape = ys[0].shape\n",
    "    \n",
    "    return indices[tr_from:tr_to], indices[va_from:va_to], indices[te_from:te_to]\n",
    "\n",
    "Dataset.shuffle_data = dataset_shuffle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_forward_postproc(self, output, y, mode=None):\n",
    "    if mode is None: mode = self.mode\n",
    "        \n",
    "    if mode == 'regression': # 1장\n",
    "        diff = output - y\n",
    "        square = np.square(diff)\n",
    "        loss = np.mean(square)\n",
    "        aux = diff\n",
    "    elif mode == 'binary': # 2장\n",
    "        entropy = sigmoid_cross_entropy_with_logits(y, output)\n",
    "        loss = np.mean(entropy)\n",
    "        aux = [y, output]\n",
    "    elif mode == 'select': # 3장 \n",
    "        entropy = softmax_cross_entropy_with_logits(y, output)\n",
    "        loss = np.mean(entropy)\n",
    "        aux = [output, y, entropy]\n",
    "        \n",
    "    return loss, aux\n",
    "\n",
    "Dataset.forward_postproc = dataset_forward_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_backprop_postproc(self, G_loss, aux, mode=None):\n",
    "    if mode is None: mode = self.mode\n",
    "        \n",
    "    if mode == 'regression': # 1장\n",
    "        diff = aux\n",
    "        shape = diff.shape\n",
    "\n",
    "        g_loss_square = np.ones(shape) / np.prod(shape)\n",
    "        g_square_diff = 2 * diff\n",
    "        g_diff_output = 1\n",
    "\n",
    "        G_square = g_loss_square * G_loss\n",
    "        G_diff = g_square_diff * G_square\n",
    "        G_output = g_diff_output * G_diff\n",
    "    elif mode == 'binary': # 2장\n",
    "        y, output = aux\n",
    "        shape = output.shape\n",
    "\n",
    "        g_loss_entropy = np.ones(shape) / np.prod(shape)\n",
    "        g_entropy_output = sigmoid_cross_entropy_with_logits_derv(y, output)\n",
    "\n",
    "        G_entropy = g_loss_entropy * G_loss\n",
    "        G_output = g_entropy_output * G_entropy\n",
    "    elif mode == 'select': # 3장 \n",
    "        output, y, entropy = aux\n",
    "\n",
    "        g_loss_entropy = 1.0 / np.prod(entropy.shape)\n",
    "        g_entropy_output = softmax_cross_entropy_with_logits_derv(y, output)\n",
    "\n",
    "        G_entropy = g_loss_entropy * G_loss\n",
    "        G_output = g_entropy_output * G_entropy\n",
    "    \n",
    "    return G_output\n",
    "\n",
    "Dataset.backprop_postproc = dataset_backprop_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_eval_accuracy(self, x, y, output, mode=None):\n",
    "    if mode is None: mode = self.mode\n",
    "        \n",
    "    if mode == 'regression': # 1장\n",
    "        mse = np.mean(np.square(output - y))\n",
    "        accuracy = 1 - np.sqrt(mse) / np.mean(y)\n",
    "    elif mode == 'binary': # 2장\n",
    "        estimate = np.greater(output, 0)\n",
    "        answer = np.equal(y, 1.0)\n",
    "        correct = np.equal(estimate, answer)\n",
    "        accuracy = np.mean(correct)\n",
    "    elif mode == 'select': # 3장 \n",
    "        estimate = np.argmax(output, axis=1)\n",
    "        answer = np.argmax(y, axis=1)\n",
    "        correct = np.equal(estimate, answer)\n",
    "        accuracy = np.mean(correct)\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "Dataset.eval_accuracy = dataset_eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_get_estimate(self, output, mode=None):\n",
    "    if mode is None: mode = self.mode\n",
    "        \n",
    "    if mode == 'regression': # 1장\n",
    "        estimate = output\n",
    "    elif mode == 'binary': # 2장\n",
    "        estimate = sigmoid(output)\n",
    "    elif mode == 'select': # 3장 \n",
    "        estimate = softmax(output)\n",
    "        \n",
    "    return estimate\n",
    "\n",
    "Dataset.get_estimate = dataset_get_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc, acc 인수값 구성, 출력문 양식 등이 달라질 경우 대비 \n",
    "def dataset_train_prt_result(self, epoch, costs, accs, acc, time1, time2):\n",
    "    print('    Epoch {}: cost={:5.3f}, accuracy={:5.3f}/{:5.3f} ({}/{} secs)'. \\\n",
    "          format(epoch, np.mean(costs), np.mean(accs), acc, time1, time2))\n",
    "\n",
    "def dataset_test_prt_result(self, name, acc, time):\n",
    "    print('Model {} test report: accuracy = {:5.3f}, ({} secs)\\n'. \\\n",
    "          format(name, acc, time))\n",
    "\n",
    "Dataset.train_prt_result = dataset_train_prt_result\n",
    "Dataset.test_prt_result = dataset_test_prt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
